{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义SOM类\n",
    "class SOM(object):\n",
    "    \"\"\"\n",
    "    Self-Organizing Feature Map\n",
    "    \"\"\"\n",
    "    def __init__(self, R, LR, S, T):\n",
    "        self.R = R\n",
    "        self.LR = LR\n",
    "        self.S = S\n",
    "                        \n",
    "        self.data = 0                          \n",
    "                      \n",
    "        self.w = 0                       \n",
    "        self.outputDist = 0                   \n",
    "\n",
    "        self.T = T                          #记录属性是离散值还是连续值\n",
    "        self.idx_BN = np.argwhere(self.T == False).squeeze()    #离散值属性编号\n",
    "        self.idx_OI = np.argwhere(self.T == True).squeeze()     #连续值属性编号\n",
    "    \n",
    "    #离散值距离计算\n",
    "    def BNd(self, x1, x2):    #T:False\n",
    "        res = np.ones(x2.shape)\n",
    "        x1 = np.tile(x1, x2.shape[0]).reshape(-1,x2.shape[1])\n",
    "        res[x1 == x2] = 0\n",
    "        return res\n",
    "    \n",
    "    #连续值距离计算\n",
    "    def OId(self, x1, x2):    #T:True\n",
    "        return np.nan_to_num(np.abs(x1 - x2), nan= 1)\n",
    "\n",
    "    #计算融合距离函数\n",
    "    def calDist(self,X1,X2):\n",
    "        #分离离散值与数值型属性\n",
    "        X1_BN = X1[self.idx_BN].astype(str)\n",
    "        X2_BN = X2[self.idx_BN].astype(str)\n",
    "        X1_OI = X1[self.idx_OI].astype(float)\n",
    "        X2_OI = X2[self.idx_OI].astype(float)\n",
    "\n",
    "        # 计算该属性值是否有效\n",
    "        delta = np.ones(X2.shape)\n",
    "        idx = np.argwhere(X1_BN == '?').squeeze()\n",
    "        delta[self.idx_BN[idx]] = 0\n",
    "        idx = np.argwhere(X2_BN == '?').squeeze()\n",
    "        if len(idx.reshape(-1,1)) == 2:\n",
    "            delta[self.idx_BN[idx[0]]][idx[1]] = 0\n",
    "        else:\n",
    "            for i in idx:\n",
    "                delta[self.idx_BN[i[0]]][i[1]] = 0\n",
    "        '''idx = np.argwhere(np.isnan(X1_OI)).squeeze()\n",
    "        delta[self.idx_OI[idx]] = 0\n",
    "        idx = np.argwhere(np.isnan(X2_OI)).squeeze()\n",
    "        if len(idx.reshape(-1,1)) == 2:\n",
    "            delta[self.idx_OI[idx[0]]][idx[1]] = 0\n",
    "        else:\n",
    "            for i in idx:\n",
    "                delta[self.idx_OI[i[0]]][i[1]] = 0'''\n",
    "        dSum = np.sum(delta, axis=0)\n",
    "\n",
    "        # 计算不同属性间距离\n",
    "        mSum = np.zeros(X2.shape[1])\n",
    "        BNd = self.BNd(X1_BN, X2_BN.T)\n",
    "        mSum += np.diagonal(np.dot(BNd, delta[self.idx_BN]))\n",
    "        OId = self.OId(X1_OI, X2_OI.T)\n",
    "        mSum += np.diagonal(np.dot(OId, delta[self.idx_OI]))\n",
    "\n",
    "        return mSum * 10 / dSum\n",
    "\n",
    "    # 更新权重\n",
    "    def update(self, data, nebor, dist):\n",
    "        res = nebor.copy()\n",
    "        data_OI = data[self.idx_OI].astype(float)\n",
    "        nebor_OI = nebor[self.idx_OI].astype(float)\n",
    "\n",
    "        #数值型权重更新\n",
    "        for i in range(len(self.idx_OI)):\n",
    "            res[self.idx_OI[i]] = nebor_OI[i] + self.LR*np.dot(data_OI[i] - nebor_OI[i], np.exp(-dist ** 2 / (2 * self.R)))\n",
    "            temp = res[self.idx_OI[i]].astype(float)\n",
    "            j = np.argwhere(temp > 1).squeeze()\n",
    "            res[self.idx_OI[i]][j] = 1\n",
    "            j = np.argwhere(temp < 0).squeeze()\n",
    "            res[self.idx_OI[i]][j] = 0\n",
    "        \n",
    "        #离散型权重更新\n",
    "        dist /= 10\n",
    "        d = min(np.average(dist),1)\n",
    "        d = max(d, 0)\n",
    "        p = np.array([1- d, d])\n",
    "        for i in self.idx_BN:\n",
    "            B = np.random.choice([True, False], p = p.ravel())\n",
    "            if B:\n",
    "                res[i] = np.repeat(data[i], nebor.shape[1])\n",
    "        return res\n",
    "    \n",
    "    #训练函数\n",
    "    def train(self, data, M, N):\n",
    "        self.data = data\n",
    "\n",
    "        #计算节点间的距离\n",
    "        self.outputDist = np.zeros((M*N,M*N))\n",
    "        for i in range(M*N):\n",
    "            for j in range(i+1, M*N):\n",
    "                    row_i = i / M\n",
    "                    col_i = i % M\n",
    "                    row_j = j / M\n",
    "                    col_j = j % M\n",
    "                    self.outputDist[i,j] = np.abs(row_i - row_j) + np.abs(col_i - col_j)\n",
    "                    self.outputDist[j,i] = self.outputDist[i,j]\n",
    "\n",
    "        w = []\n",
    "        #随机生成权重\n",
    "        '''Nominal_dict = [\n",
    "            ['Caucasian', 'AfricanAmerican', '?', 'Hispanic', 'Other', 'Asian'],\n",
    "            ['Female', 'Male'],\n",
    "            [i for i in range(0,10)],\n",
    "            [1, 2, 3, 5, 6],\n",
    "            [1, 2, 3, 5, 6, 18, 22, 25],\n",
    "            [1, 2, 4, 6, 7, 17],\n",
    "            ['?', 'InternalMedicine', 'Family/GeneralPractice', 'Emergency/Trauma', 'Cardiology', 'Surgery-General', 'Orthopedics', 'Orthopedics-Reconstructive'\n",
    "                'Radiologist', 'Nephrology'],\n",
    "            ['None', '>8', 'Norm', '>7'],\n",
    "            ['No', 'Steady', 'Up', 'Down'],\n",
    "            ['No', 'Steady', 'Up', 'Down'],\n",
    "            ['No', 'Steady', 'Up', 'Down'],\n",
    "            ['No', 'Steady', 'Up', 'Down'],\n",
    "            ['No', 'Steady'],\n",
    "            ['No', 'Steady'],\n",
    "            ['No', 'Steady', 'Up', 'Down'],\n",
    "            ['No', 'Ch'],\n",
    "            ['Yes', 'No']\n",
    "        ]\n",
    "        cnt = 0\n",
    "        for b in self.T:\n",
    "            if b:\n",
    "                w.append(np.random.random(M*N))\n",
    "            else:\n",
    "                j = np.random.randint(0,len(Nominal_dict[cnt]),(1,M*N)).squeeze()\n",
    "                w.append(np.array([Nominal_dict[cnt][k] for k in j]))\n",
    "                cnt += 1'''\n",
    "        #抽取样本作为权重\n",
    "        idx_sample = np.random.randint(0, data.shape[0], M*N)\n",
    "        for i in range(M*N):\n",
    "            w.append(data[idx_sample[i]])\n",
    "        w = np.array(w).T\n",
    "\n",
    "        ##2 竞争\n",
    "        for i in range(self.S):\n",
    "            data = self.data[np.random.randint(0, self.data.shape[0], 1)[0], :]\n",
    "            dist = self.calDist(data,w)\n",
    "            winPointIdx = np.argmin(dist)\n",
    "\n",
    "            ##3 迭代\n",
    "            winR = np.nonzero(self.outputDist[winPointIdx]<self.R)[0]\n",
    "            ww = []\n",
    "            for k in range(len(w)):\n",
    "                ww.append(w[k][winR])\n",
    "            ww = self.update(data, np.array(ww), dist[winR])\n",
    "            for k in range(len(w)):\n",
    "                w[k][winR] = ww[k]\n",
    "\n",
    "        self.w = w\n",
    "\n",
    "    #聚类标签\n",
    "    def cluster(self, data):\n",
    "        res = []\n",
    "        for i in range(data.shape[0]):\n",
    "            d = self.dist(data[i], self.w)\n",
    "            res.append(np.argmin(d))\n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "df = pd.read_csv('.\\dataset_diabetes\\proprecessing_data.csv')   \n",
    "\n",
    "T = np.array([False, False, False, False, False, False, True, False, True, True, True, True, True,\n",
    "        True, True, True, True, True, False, False, False, False, False, False, False, False, False, \n",
    "        False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据补充处理\n",
    "# 删除性别未知的数据\n",
    "dropID = []\n",
    "for value in df.index.values:\n",
    "    if df.loc[value,'gender'] == 'Unknown/Invalid':\n",
    "        dropID.append(value)\n",
    "df = df.drop(dropID)\n",
    "\n",
    "# 离散值替换：转为darray类型\n",
    "data_set = df.to_numpy().T\n",
    "\n",
    "# Ordianl变量改为Nominal类型\n",
    "le = preprocessing.LabelEncoder()    #获取一个LabelEncoder\n",
    "le = le.fit([\"[0-10)\", \"[10-20)\", \"[20-30)\", \"[30-40)\", \"[40-50)\", \"[50-60)\", \"[60-70)\", \"[70-80)\", \"[80-90)\", \"[90-100)\"])      #训练LabelEncoder\n",
    "data_set[2] = le.transform(data_set[2])                #使用训练好的LabelEncoder对原数据进行编码\n",
    "scaler = preprocessing.MinMaxScaler() \n",
    "\n",
    "# Interval-based数据归一化\n",
    "idx = [6, 8, 9, 10, 11, 12, 13, 17]\n",
    "idx_mix = [14, 15, 16]\n",
    "scaler = scaler.fit(data_set[idx].T) \n",
    "data_set[idx] = scaler.transform(data_set[idx].T).T\n",
    "\n",
    "for i in idx_mix:   #无效值替代\n",
    "    subdata_set = np.array([str(j) for j in data_set[i]])\n",
    "    invalid_char = ['V','E','?']\n",
    "    idx_nan = np.array([])\n",
    "    for c in invalid_char:\n",
    "        char_count = np.char.count(subdata_set, c)\n",
    "        idx_nan = np.append(idx_nan, np.argwhere(char_count != 0))\n",
    "    idx_nan = np.unique(idx_nan).astype(int)\n",
    "    subdata_set[idx_nan] = '0'\n",
    "    subdata_set = subdata_set.astype(float)\n",
    "    data_set[i] = scaler.fit_transform(subdata_set.reshape(-1,1)).reshape(1,-1).squeeze()\n",
    "\n",
    "data_set = data_set.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOM聚类\n",
    "M, N = 7, 7                                     #输出层拓扑形状\n",
    "som = SOM(5, 0.001, 400000, T)             \n",
    "som.train(data_set, M= M, N= N)\n",
    "cluster_label = som.cluster(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存结果\n",
    "np.save('./result/5_001_10_10_cluster_s3.npy', cluster_label)  \n",
    "np.save('./result/5_001_10_10_w_s3.npy', som.w)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94186ee46dd20d9135eb93318a31c12944db0bab97754bb10895fc1a10cecd0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
